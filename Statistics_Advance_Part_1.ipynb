{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Theory Questions**"
      ],
      "metadata": {
        "id": "Fo_955w1HoQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. What is a random variable in probability theory?\n",
        "A random variable is a numerical outcome of a random phenomenon. It assigns a real number to each outcome in a sample space. Random variables are essential in statistics and probability theory, as they help quantify uncertain events and are used to define probability distributions that describe how values are likely to occur in practice.\n",
        "\n",
        "##2. What are the types of random variables?\n",
        "Random variables are mainly of two types: discrete and continuous. Discrete random variables take on countable values (like the result of a die roll), whereas continuous random variables can take on any value within a range (such as height or weight). Both types are used to model real-world random processes.\n",
        "\n",
        "##3. What is the difference between discrete and continuous distributions?\n",
        "A discrete distribution describes the probability of outcomes of a discrete random variable, often involving whole numbers. A continuous distribution describes a continuous random variable and uses probability density functions since individual points have zero probability. Examples include the binomial (discrete) and normal (continuous) distributions.\n",
        "\n",
        "##4. What are probability distribution functions (PDF)?\n",
        "A probability distribution function (PDF) describes how the probabilities are distributed over the values of a continuous random variable. It represents the relative likelihood of a random variable taking a specific value. The area under the PDF curve over a range gives the probability of falling within that range.\n",
        "\n",
        "##5. How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)?\n",
        "The CDF gives the probability that a random variable is less than or equal to a certain value. It is the integral of the PDF. While PDFs show the density at each value, CDFs show the accumulated probability. CDFs apply to both discrete and continuous random variables.\n",
        "\n",
        "##6. What is a discrete uniform distribution?\n",
        "A discrete uniform distribution is one where each outcome in a finite sample space has an equal probability of occurring. An example is rolling a fair six-sided die, where each side (1 to 6) has an equal probability of 1/6. It’s one of the simplest forms of probability distributions.\n",
        "\n",
        "##7. What are the key properties of a Bernoulli distribution?\n",
        "The Bernoulli distribution has two outcomes: success (1) and failure (0), with probability p of success. Its key properties include a mean of p and variance of p(1 - p). It forms the basis of the binomial distribution, which models multiple Bernoulli trials.\n",
        "\n",
        "##8. What is the binomial distribution, and how is it used in probability?\n",
        "The binomial distribution models the number of successes in a fixed number of independent Bernoulli trials, each with the same probability p. It’s used in scenarios like coin tosses or pass/fail testing, where each trial has two outcomes and the number of trials is known.\n",
        "\n",
        "##9. What is the Poisson distribution and where is it applied?\n",
        "The Poisson distribution models the number of events occurring in a fixed interval of time or space when the events are rare and occur independently. It's used in scenarios like counting calls at a call center per hour or the number of accidents at an intersection per week.\n",
        "\n",
        "##10. What is a continuous uniform distribution?\n",
        "A continuous uniform distribution assumes that all outcomes in an interval are equally likely. For example, a bus arriving at any time between 10 and 11 AM is uniformly distributed. The PDF is constant, and the distribution is characterized by its lower and upper bounds.\n",
        "\n",
        "##11. What are the characteristics of a normal distribution?\n",
        "A normal distribution is symmetric, bell-shaped, and defined by its mean and standard deviation. It describes many natural phenomena, such as heights and test scores. The area under the curve represents probability, and about 68% of data lies within 1 standard deviation of the mean.\n",
        "\n",
        "##12. What is the standard normal distribution, and why is it important?\n",
        "The standard normal distribution is a special case of the normal distribution with a mean of 0 and a standard deviation of 1. It simplifies statistical calculations and is used to compute Z-scores, which standardize data for hypothesis testing and confidence interval estimation.\n",
        "\n",
        "##13. What is the Central Limit Theorem (CLT), and why is it critical in statistics?\n",
        "The Central Limit Theorem states that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases, regardless of the original population's distribution. It allows statisticians to use normal-based inference even when the underlying data is not normally distributed.\n",
        "\n",
        "##14. How does the Central Limit Theorem relate to the normal distribution?\n",
        "The Central Limit Theorem justifies the use of the normal distribution for estimating means from large samples. It ensures that even if the population is skewed or non-normal, the distribution of the sample mean will be approximately normal for large enough samples.\n",
        "\n",
        "##15. What is the application of Z statistics in hypothesis testing?\n",
        "Z-statistics are used to test hypotheses about population means when the population variance is known. It standardizes the sample mean into a Z-score, which is compared against critical values from the standard normal distribution to determine statistical significance at various confidence levels.\n",
        "\n",
        "##16. How do you calculate a Z-score, and what does it represent?\n",
        "The Z-score is calculated as:\n",
        "Z = (X - μ) / σ,\n",
        "where X is the value, μ is the mean, and σ is the standard deviation. It represents how many standard deviations a value is from the mean, helping compare values across different distributions.\n",
        "\n",
        "##17. What are point estimates and interval estimates in statistics?\n",
        "A point estimate provides a single value as an estimate of a population parameter (e.g., sample mean for population mean). An interval estimate provides a range of values (confidence interval) within which the parameter is likely to fall, giving a measure of certainty around the estimate.\n",
        "\n",
        "##18. What is the significance of confidence intervals in statistical analysis?\n",
        "Confidence intervals give a range of plausible values for a population parameter based on sample data. They indicate the reliability of an estimate. For instance, a 95% confidence interval means that if you repeated the experiment many times, 95% of the intervals would contain the true parameter.\n",
        "\n",
        "##19. What is the relationship between a Z-score and a confidence interval?\n",
        "Z-scores define the bounds of confidence intervals in normal distributions. For example, a Z-score of ±1.96 corresponds to a 95% confidence interval. The Z-score is multiplied by the standard error to determine the margin of error, forming the interval around the sample mean.\n",
        "\n",
        "##20. How are Z-scores used to compare different distributions?\n",
        "Z-scores standardize values from different distributions, allowing comparison across different units or scales. For example, test scores from different exams can be compared using Z-scores. A higher Z-score means the value is further above the mean relative to its standard deviation.\n",
        "\n",
        "##21. What are the assumptions for applying the Central Limit Theorem?\n",
        "To apply the Central Limit Theorem, the sample size should be sufficiently large (commonly n ≥ 30). Observations should be independent, and the population should have a finite mean and variance. For small samples, the population must be approximately normal to ensure validity.\n",
        "\n",
        "##22. What is the concept of expected value in a probability distribution?\n",
        "The expected value is the long-run average or mean of a random variable. It is calculated by multiplying each possible outcome by its probability and summing the results. It represents the value you expect on average after many repetitions of an experiment.\n",
        "\n",
        "##23. How does a probability distribution relate to the expected outcome of a random variable?\n",
        "A probability distribution describes the likelihood of each outcome of a random variable. The expected outcome, or expected value, is derived from this distribution and provides a single summary measure of the average result across many trials or observations."
      ],
      "metadata": {
        "id": "R_6-t7sTHjt2"
      }
    }
  ]
}